{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ed64f945-a88d-4e5a-954d-bcc9ecc9683c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device is: cpu\n",
      "mkdir: output: File exists\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import copy\n",
    "import gc\n",
    "import itertools\n",
    "import joblib\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import scipy as sp\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "# import wandb\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ======= OPTIONS =========\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Current device is: {device}\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "!mkdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1165ef-c087-4a13-bb89-87b50fad6dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4a0555-1f7a-447e-a92c-a35f8b080292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8445d08c-9d56-4686-af7d-c7a834b4321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n",
      "tokenizers.__version__: 0.15.0\n",
      "transformers.__version__: 4.35.2\n"
     ]
    }
   ],
   "source": [
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef8523d4-7c2c-4f20-97e8-62bc9c7d7869",
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    APEX = True # Automatic Precision Enabled\n",
    "    BATCH_SCHEDULER = True\n",
    "    BATCH_SIZE_TRAIN = 32\n",
    "    BATCH_SIZE_VALID = 16\n",
    "    BETAS = (0.9, 0.999)\n",
    "    DEBUG = False\n",
    "    DECODER_LR = 2e-5\n",
    "    ENCODER_LR = 2e-5\n",
    "    EPOCHS = 5\n",
    "    EPS = 1e-6\n",
    "    FOLDS = 2\n",
    "    GRADIENT_ACCUMULATION_STEPS = 1\n",
    "    GRADIENT_CHECKPOINTING = True\n",
    "    MAX_GRAD_NORM=1000\n",
    "    MAX_LEN = 512\n",
    "    MIN_LR = 1e-6\n",
    "    MODEL = \"deberta-v3-base\"\n",
    "    NUM_CYCLES = 0.5\n",
    "    NUM_WARMUP_STEPS = 0\n",
    "    NUM_WORKERS = multiprocessing.cpu_count()\n",
    "    PRINT_FREQ = 20\n",
    "    SCHEDULER = 'cosine' # ['linear', 'cosine']\n",
    "    SEED = 27\n",
    "    TRAIN = True\n",
    "    TRAIN_FOLDS = [0, 1]\n",
    "    WANDB = False\n",
    "    WEIGHT_DECAY = 0.01\n",
    "\n",
    "    \n",
    "class paths:\n",
    "    OUTPUT_DIR = \"output\"\n",
    "    EXTERNAL_DATA = \"mobile_dataset_082023.xlsx\"\n",
    "    # TRAIN_PROMPTS = \"/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\"\n",
    "    # TRAIN_ESSAYS = \"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\"\n",
    "    # TEST_ESSAYS = \"/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\"\n",
    "    \n",
    "\n",
    "if config.DEBUG:\n",
    "    config.EPOCHS = 2\n",
    "    config.TRAIN_FOLDS = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5d4e85a6-93f6-4e1a-aa22-60bbf007cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config_dict(config):\n",
    "    \"\"\"\n",
    "    Return the config, which is originally a class, as a Python dictionary.\n",
    "    \"\"\"\n",
    "    config_dict = dict((key, value) for key, value in config.__dict__.items() \n",
    "    if not callable(value) and not key.startswith('__'))\n",
    "    return config_dict\n",
    "\n",
    "\n",
    "def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "         'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "         'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "        {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "         'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "    ]\n",
    "    return optimizer_parameters\n",
    "\n",
    "\n",
    "# def get_logger(filename=paths.OUTPUT_DIR):\n",
    "#     from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "#     logger = getLogger(__name__)\n",
    "#     logger.setLevel(INFO)\n",
    "#     handler1 = StreamHandler()\n",
    "#     handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "#     handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "#     handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "#     logger.addHandler(handler1)\n",
    "#     logger.addHandler(handler2)\n",
    "#     return logger\n",
    "\n",
    "\n",
    "def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "    if cfg.SCHEDULER == 'linear':\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=cfg.NUM_WARMUP_STEPS,\n",
    "            num_training_steps=num_train_steps\n",
    "        )\n",
    "    elif cfg.SCHEDULER == 'cosine':\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=cfg.NUM_WARMUP_STEPS,\n",
    "            num_training_steps=num_train_steps, num_cycles=cfg.NUM_CYCLES\n",
    "        )\n",
    "    return scheduler\n",
    "    \n",
    "\n",
    "def get_score(y_trues, y_preds):\n",
    "    # probabilities = [np.exp(v)/np.sum([np.exp(val) for val in y_preds]) for v in y_preds]\n",
    "    print(len(y_trues), len(y_preds))\n",
    "    score = roc_auc_score(y_trues, y_preds)\n",
    "    return score\n",
    "\n",
    "\n",
    "def seed_everything(seed=20):\n",
    "    \"\"\"Seed everything to ensure reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "\n",
    "def sep():\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))  \n",
    "    \n",
    "# LOGGER = get_logger()\n",
    "seed_everything(seed=config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d5643b06-6821-41b8-894b-7cf32e8c2829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "\n",
    "notes = \"\"\n",
    "\n",
    "if config.WANDB:\n",
    "    try:\n",
    "        from kaggle_secrets import UserSecretsClient\n",
    "        user_secrets = UserSecretsClient()\n",
    "        secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n",
    "        wandb.login(key=secret_value_0)\n",
    "        anony = None\n",
    "    except:\n",
    "        anony = \"must\"\n",
    "        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
    "\n",
    "    run = wandb.init(project='CommonLit', \n",
    "                     name=\"test_1\",\n",
    "                     config=get_config_dict(config),\n",
    "                     group=\"anti_overfit\",\n",
    "                     job_type=\"train\",\n",
    "                     notes=notes,\n",
    "                     anonymous=anony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d6f30e-ff73-4086-83c7-c4116dfd141d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f27ef468-68e2-45ca-9773-16dce50a6295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intents</th>\n",
       "      <th>text</th>\n",
       "      <th>sm</th>\n",
       "      <th>scenario_id</th>\n",
       "      <th>masked_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/сбермобайл. прочее</td>\n",
       "      <td>Как проверить есть ли автоплатеж?</td>\n",
       "      <td>СберМобайл. Прочее</td>\n",
       "      <td>ESM009</td>\n",
       "      <td>как проверить есть ли автоплатеж?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/сбермобайл. прочее</td>\n",
       "      <td>Вчера бросила 110 руб на номер  подключите</td>\n",
       "      <td>СберМобайл. Прочее</td>\n",
       "      <td>ESM009</td>\n",
       "      <td>вчера бросила 111 руб на номер  подключите</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/сбермобайл. прочее</td>\n",
       "      <td>Вчера ничего не ответели.</td>\n",
       "      <td>СберМобайл. Прочее</td>\n",
       "      <td>ESM009</td>\n",
       "      <td>вчера ничего не ответели.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/сбермобайл. прочее</td>\n",
       "      <td>что скажете по проблеме?</td>\n",
       "      <td>СберМобайл. Прочее</td>\n",
       "      <td>ESM009</td>\n",
       "      <td>что скажете по проблеме?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/сбермобайл. прочее</td>\n",
       "      <td>Доступ к фото</td>\n",
       "      <td>СберМобайл. Прочее</td>\n",
       "      <td>ESM009</td>\n",
       "      <td>доступ к фото</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               intents                                        text                  sm scenario_id                                 masked_text\n",
       "0  /сбермобайл. прочее           Как проверить есть ли автоплатеж?  СберМобайл. Прочее      ESM009           как проверить есть ли автоплатеж?\n",
       "1  /сбермобайл. прочее  Вчера бросила 110 руб на номер  подключите  СберМобайл. Прочее      ESM009  вчера бросила 111 руб на номер  подключите\n",
       "2  /сбермобайл. прочее                   Вчера ничего не ответели.  СберМобайл. Прочее      ESM009                   вчера ничего не ответели.\n",
       "3  /сбермобайл. прочее                    что скажете по проблеме?  СберМобайл. Прочее      ESM009                    что скажете по проблеме?\n",
       "4  /сбермобайл. прочее                               Доступ к фото  СберМобайл. Прочее      ESM009                               доступ к фото"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_df = pd.read_csv(paths.TRAIN_ESSAYS, sep=',')\n",
    "external_df = pd.read_excel(paths.EXTERNAL_DATA)\n",
    "# train_prompts = pd.read_csv(paths.TRAIN_PROMPTS, sep=',')\n",
    "# print(f\"Train essays dataframe has shape: {train_df.shape}\"), sep()\n",
    "# print(f\"External essays dataframe has shape: {external_df.shape}\"), sep()\n",
    "# print(f\"Train prompts dataframe has shape: {train_prompts.shape}\"), sep()\n",
    "# display(train_df.head())\n",
    "display(external_df.head())\n",
    "# display(train_prompts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d131033-2beb-44f5-acdd-1731a6e068fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "959d2fec-17fe-47e8-9945-940bd7650788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataframe has shape: (50386, 3)\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Как проверить есть ли автоплатеж?</td>\n",
       "      <td>СберМобайл. Прочее</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Вчера бросила 110 руб на номер  подключите</td>\n",
       "      <td>СберМобайл. Прочее</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Вчера ничего не ответели.</td>\n",
       "      <td>СберМобайл. Прочее</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>что скажете по проблеме?</td>\n",
       "      <td>СберМобайл. Прочее</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Доступ к фото</td>\n",
       "      <td>СберМобайл. Прочее</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                        text           generated\n",
       "0   0           Как проверить есть ли автоплатеж?  СберМобайл. Прочее\n",
       "1   1  Вчера бросила 110 руб на номер  подключите  СберМобайл. Прочее\n",
       "2   2                   Вчера ничего не ответели.  СберМобайл. Прочее\n",
       "3   3                    что скажете по проблеме?  СберМобайл. Прочее\n",
       "4   4                               Доступ к фото  СберМобайл. Прочее"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = external_df\n",
    "train_df['id'] = train_df.reset_index()['index']\n",
    "train_df.rename(columns={'sm':'generated'}, inplace=True)\n",
    "train_df = train_df[['id', 'text','generated']]\n",
    "print(f\"Train dataframe has shape: {train_df.shape}\"), sep()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8713303-3943-4da4-bc0c-ca93ba49cffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2f2fe219-2111-4b4d-9e92-7f5b1d25d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df.iloc[np.random.choice(train_df.index, 100)], \\\n",
    "                      train_df.drop_duplicates(['generated'])]).drop_duplicates(['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "872e17be-2cde-4dae-82be-9e36a45b1403",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_mapper = dict(zip(sorted(list(train_df['generated'].unique())),range(1, train_df['generated'].nunique()+ 1)))\n",
    "train_df['generated'] = train_df['generated'].map(topic_mapper)\n",
    "train_df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b661cc5a-0261-419f-a6ef-abe641e58c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  generated\n",
      "0.0   15           7\n",
      "      1            6\n",
      "      14           2\n",
      "      17           1\n",
      "      6            1\n",
      "      5            1\n",
      "      4            1\n",
      "      7            1\n",
      "      21           1\n",
      "      28           1\n",
      "      10           1\n",
      "      20           1\n",
      "      9            1\n",
      "      2            1\n",
      "1.0   15           7\n",
      "      1            6\n",
      "      14           2\n",
      "      20           1\n",
      "      2            1\n",
      "      3            1\n",
      "      4            1\n",
      "      5            1\n",
      "      8            1\n",
      "      10           1\n",
      "      12           1\n",
      "      16           1\n",
      "      21           1\n",
      "      23           1\n",
      "2.0   15           7\n",
      "      1            6\n",
      "      14           2\n",
      "      27           1\n",
      "      22           1\n",
      "      26           1\n",
      "      2            1\n",
      "      3            1\n",
      "      12           1\n",
      "      13           1\n",
      "      16           1\n",
      "      18           1\n",
      "      20           1\n",
      "      21           1\n",
      "3.0   15           7\n",
      "      1            6\n",
      "      14           2\n",
      "      27           1\n",
      "      2            1\n",
      "      3            1\n",
      "      11           1\n",
      "      12           1\n",
      "      13           1\n",
      "      18           1\n",
      "      19           1\n",
      "      21           1\n",
      "      24           1\n",
      "4.0   15           7\n",
      "      1            6\n",
      "      2            1\n",
      "      6            1\n",
      "      7            1\n",
      "      12           1\n",
      "      14           1\n",
      "      18           1\n",
      "      19           1\n",
      "      20           1\n",
      "      21           1\n",
      "      24           1\n",
      "      25           1\n",
      "      28           1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24437</td>\n",
       "      <td>отключить настройки виртуальной симки</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21318</td>\n",
       "      <td>У меня закончился интернет</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33245</td>\n",
       "      <td>блч</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47963</td>\n",
       "      <td>Деньги не перечислили</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6784</td>\n",
       "      <td>Можно ещё вопрос?</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                   text  generated  fold\n",
       "0  24437  отключить настройки виртуальной симки          2   0.0\n",
       "1  21318             У меня закончился интернет          5   0.0\n",
       "2  33245                                    блч         15   0.0\n",
       "3  47963                  Деньги не перечислили         27   2.0\n",
       "4   6784                      Можно ещё вопрос?         15   0.0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "X = train_df.loc[:, train_df.columns != \"generated\"]\n",
    "y = train_df.loc[:, train_df.columns == \"generated\"]\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
    "    train_df.loc[valid_index, \"fold\"] = i\n",
    "    \n",
    "print(train_df.groupby(\"fold\")[\"generated\"].value_counts())\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c300efc0-c199-45d5-a5ae-0396221f90aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DebertaV2TokenizerFast(name_or_path='deberta-v3-base', vocab_size=128000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128000: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.MODEL)\n",
    "tokenizer.save_pretrained(paths.OUTPUT_DIR + '/tokenizer/')\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2eedaf9b-27d0-4bf2-bcce-f2e3a6fe8034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 13350.02it/s]\n"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "tqdm_loader = tqdm(train_df['text'].fillna(\"\").values, total=len(train_df))\n",
    "for text in tqdm_loader:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "    lengths.append(length)\n",
    "    \n",
    "# config.MAX_LEN = max(lengths) + 3 # cls & sep & sep\n",
    "# print(f\"max_len: {config.MAX_LEN}\")\n",
    "# _ = plt.hist(lengths, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "127cf561-aaf9-42d1-9aa4-9d36754c0a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(cfg, text, tokenizer):\n",
    "    \"\"\"\n",
    "    This function tokenizes the input text with the configured padding and truncation. Then,\n",
    "    returns the input dictionary, which contains the following keys: \"input_ids\",\n",
    "    \"token_type_ids\" and \"attention_mask\". Each value is a torch.tensor.\n",
    "    :param cfg: configuration class with a TOKENIZER attribute.\n",
    "    :param text: a numpy array where each value is a text as string.\n",
    "    :return inputs: python dictionary where values are torch tensors.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text, \n",
    "        return_tensors=None, \n",
    "        add_special_tokens=True, \n",
    "        max_length=cfg.MAX_LEN,\n",
    "        padding='max_length', # TODO: check padding to max sequence in batch\n",
    "        truncation=True\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long) # TODO: check dtypes\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def collate(inputs):\n",
    "    \"\"\"\n",
    "    It truncates the inputs to the maximum sequence length in the batch. \n",
    "    \"\"\"\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max()) # Get batch's max sequence length\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, cfg, df, tokenizer):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['text'].values\n",
    "        self.labels = df['generated'].values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text_ids = df['id'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        output = {}\n",
    "        output[\"inputs\"] = prepare_input(self.cfg, self.texts[item], self.tokenizer)\n",
    "        output[\"labels\"] = torch.tensor(self.labels[item], dtype=torch.float) # TODO: check dtypes\n",
    "        output[\"ids\"] = self.text_ids[item]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bece2f-5735-486c-9cb7-6e83fb1bd10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2bbb4f2f-3743-4b2a-98a4-cf12c967cff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.DEBUG:\n",
    "    # ======== SPLIT ==========\n",
    "    fold = 0\n",
    "    train_folds = train_df[train_df['fold'] != fold].reset_index(drop=True)\n",
    "    valid_folds = train_df[train_df['fold'] == fold].reset_index(drop=True)\n",
    "    valid_labels = valid_folds['generated'].values\n",
    "\n",
    "    # ======== DATASETS ==========\n",
    "    train_dataset = CustomDataset(config, train_folds, tokenizer)\n",
    "    valid_dataset = CustomDataset(config, valid_folds, tokenizer)\n",
    "\n",
    "    # ======== DATALOADERS ==========\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=config.BATCH_SIZE_TRAIN, # TODO: split into train and valid\n",
    "                              shuffle=True,\n",
    "                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=config.BATCH_SIZE_VALID,\n",
    "                              shuffle=False,\n",
    "                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # === Let's check one sample ===\n",
    "    sample = train_dataset[0]\n",
    "    print(f\"Encoding keys: {sample.keys()} \\n\") \n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6c96b-dd6d-4fb3-b34a-03d32dfdfaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "565f7a1c-54ac-47a6-9713-05b8529a8545",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "    \n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.dropout = 0.2\n",
    "        # Load config by inferencing it from the model name.\n",
    "        if config_path is None: \n",
    "            self.config = AutoConfig.from_pretrained(cfg.MODEL, output_hidden_states=True)\n",
    "            self.config.hidden_dropout = 0.\n",
    "            self.config.hidden_dropout_prob = 0.\n",
    "            self.config.attention_dropout = 0.\n",
    "            self.config.attention_probs_dropout_prob = 0.\n",
    "        # Load config from a file.\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        \n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.MODEL, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)\n",
    "        \n",
    "        if self.cfg.GRADIENT_CHECKPOINTING:\n",
    "            self.model.gradient_checkpointing_enable()\n",
    "          \n",
    "        # Add MeanPooling and Linear head at the end to transform the Model into a RegressionModel\n",
    "        self.pool = MeanPooling()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(16, 27)\n",
    "        )\n",
    "        self._init_weights(self.head)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"\n",
    "        This method initializes weights for different types of layers. The type of layers \n",
    "        supported are nn.Linear, nn.Embedding and nn.LayerNorm.\n",
    "        \"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        \"\"\"\n",
    "        This method makes a forward pass through the model, get the last hidden state (embedding)\n",
    "        and pass it through the MeanPooling layer.\n",
    "        \"\"\"\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        This method makes a forward pass through the model, the MeanPooling layer and finally\n",
    "        then through the Linear layer to get a regression value.\n",
    "        \"\"\"\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.head(feature)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "58f518c9-7106-4449-9f5b-2483e6b7e250",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    \"\"\"One epoch training pass.\"\"\"\n",
    "    model.train() # set model in train mode\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=config.APEX) # Automatic Mixed Precision tries to match each op to its appropriate datatype.\n",
    "    losses = AverageMeter() # initiate AverageMeter to track the loss.\n",
    "    start = end = time.time() # track the execution time.\n",
    "    global_step = 0\n",
    "    \n",
    "    # ========== ITERATE OVER TRAIN BATCHES ============\n",
    "    with tqdm(train_loader, unit=\"train_batch\", desc='Train') as tqdm_train_loader:\n",
    "        for step, batch in enumerate(tqdm_train_loader):\n",
    "            inputs = batch.pop(\"inputs\")\n",
    "            labels = batch.pop(\"labels\")\n",
    "            inputs = collate(inputs) # collate inputs\n",
    "            for k, v in inputs.items(): # send each tensor value to `device`\n",
    "                inputs[k] = v.to(device)\n",
    "            labels = labels.to(device) # send labels to `device`\n",
    "            batch_size = labels.size(0)\n",
    "            with torch.cuda.amp.autocast(enabled=config.APEX):\n",
    "                y_preds = model(inputs) # forward propagation pass\n",
    "                print(y_preds, labels)\n",
    "                loss = criterion(y_preds, labels.to(torch.long).to(device)) # get loss\n",
    "            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n",
    "            losses.update(loss.item(), batch_size) # update loss function tracking\n",
    "            scaler.scale(loss).backward() # backward propagation pass\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.MAX_GRAD_NORM)\n",
    "\n",
    "            if (step + 1) % config.GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "                scaler.step(optimizer) # update optimizer parameters\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad() # zero out the gradients\n",
    "                global_step += 1\n",
    "                if config.BATCH_SCHEDULER:\n",
    "                    scheduler.step() # update learning rate\n",
    "            end = time.time() # get finish time\n",
    "\n",
    "            # ========== LOG INFO ==========\n",
    "            if step % config.PRINT_FREQ == 0 or step == (len(train_loader)-1):\n",
    "                print('Epoch: [{0}][{1}/{2}] '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.avg:.4f} '\n",
    "                      'Grad: {grad_norm:.4f}  '\n",
    "                      'LR: {lr:.8f}  '\n",
    "                      .format(epoch+1, step, len(train_loader), \n",
    "                              remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                              loss=losses,\n",
    "                              grad_norm=grad_norm,\n",
    "                              lr=scheduler.get_lr()[0]))\n",
    "            if config.WANDB:\n",
    "                wandb.log({f\"[fold_{fold}] train loss\": losses.val,\n",
    "                           f\"[fold_{fold}] lr\": scheduler.get_lr()[0]})\n",
    "\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_epoch(valid_loader, model, criterion, device):\n",
    "    model.eval() # set model in evaluation mode\n",
    "    losses = AverageMeter() # initiate AverageMeter for tracking the loss.\n",
    "    prediction_dict = {}\n",
    "    preds = []\n",
    "    start = end = time.time() # track the execution time.\n",
    "    with tqdm(valid_loader, unit=\"valid_batch\", desc='Validation') as tqdm_valid_loader:\n",
    "        for step, batch in enumerate(tqdm_valid_loader):\n",
    "            inputs = batch.pop(\"inputs\")\n",
    "            labels = batch.pop(\"labels\")\n",
    "            ids = batch.pop(\"ids\")\n",
    "            inputs = collate(inputs) # collate inputs\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.to(device) # send inputs to device\n",
    "            labels = labels.to(device)\n",
    "            batch_size = labels.size(0)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                y_preds = model(inputs) # forward propagation pass\n",
    "                loss = criterion(y_preds, labels.unsqueeze(1)) # get loss\n",
    "            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n",
    "            losses.update(loss.item(), batch_size) # update loss function tracking\n",
    "            preds.append(y_preds.to('cpu').numpy()) # save predictions\n",
    "            end = time.time() # get finish time\n",
    "\n",
    "            # ========== LOG INFO ==========\n",
    "            if step % config.PRINT_FREQ == 0 or step == (len(valid_loader)-1):\n",
    "                print('EVAL: [{0}/{1}] '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.avg:.4f} '\n",
    "                      .format(step, len(valid_loader),\n",
    "                              loss=losses,\n",
    "                              remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
    "            if config.WANDB:\n",
    "                wandb.log({f\"[fold_{fold}] val loss\": losses.val})\n",
    "                \n",
    "    prediction_dict[\"predictions\"] = np.concatenate(preds) # np.array() of shape (fold_size, target_cols)\n",
    "    prediction_dict[\"ids\"] = ids\n",
    "    return losses.avg, prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "a4854b6f-0b46-4cc8-8ea4-7b2f7fdc9e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(folds, fold):\n",
    "    \n",
    "    print(f\"========== Fold: {fold} training ==========\")\n",
    "\n",
    "    # ======== SPLIT ==========\n",
    "    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n",
    "    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    valid_labels = valid_folds['generated'].values\n",
    "\n",
    "    # ======== DATASETS ==========\n",
    "    train_dataset = CustomDataset(config, train_folds, tokenizer)\n",
    "    valid_dataset = CustomDataset(config, valid_folds, tokenizer)\n",
    "    \n",
    "    # ======== DATALOADERS ==========\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=config.BATCH_SIZE_TRAIN, # TODO: split into train and valid\n",
    "                              shuffle=True,\n",
    "                              pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=config.BATCH_SIZE_VALID,\n",
    "                              shuffle=False,\n",
    "                              pin_memory=True, drop_last=False)\n",
    "    \n",
    "    # ======== MODEL ==========\n",
    "    model = CustomModel(config, config_path=None, pretrained=True)\n",
    "    torch.save(model.config, paths.OUTPUT_DIR + '/config.pth')\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer_parameters = get_optimizer_params(model,\n",
    "                                                encoder_lr=config.ENCODER_LR, \n",
    "                                                decoder_lr=config.DECODER_LR,\n",
    "                                                weight_decay=config.WEIGHT_DECAY)\n",
    "    optimizer = AdamW(optimizer_parameters,\n",
    "                      lr=config.ENCODER_LR,\n",
    "                      eps=config.EPS,\n",
    "                      betas=config.BETAS)\n",
    "    \n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=1e-5,\n",
    "        epochs=config.EPOCHS,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.1,\n",
    "        anneal_strategy=\"cos\",\n",
    "        final_div_factor=100,\n",
    "    )\n",
    "\n",
    "    # ======= LOSS ==========\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_score = -np.inf\n",
    "    # ====== ITERATE EPOCHS ========\n",
    "    for epoch in range(config.EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # ======= TRAIN ==========\n",
    "        avg_loss = train_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # ======= EVALUATION ==========\n",
    "        avg_val_loss, prediction_dict = valid_epoch(valid_loader, model, criterion, device)\n",
    "        predictions = prediction_dict[\"predictions\"]\n",
    "        # ======= SCORING ==========\n",
    "        softmax = lambda y: [np.exp(v)/np.sum([np.exp(val) for val in y]) for v in y]\n",
    "        score = get_score(valid_labels, predictions)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        # print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        # print(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
    "        \n",
    "        if config.WANDB:\n",
    "            wandb.log({f\"[fold_{fold}] epoch\": epoch+1, \n",
    "                       f\"[fold_{fold}] avg_train_loss\": avg_loss, \n",
    "                       f\"[fold_{fold}] avg_val_loss\": avg_val_loss,\n",
    "                       f\"[fold_{fold}] score\": score})\n",
    "            \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            # print(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save(model.state_dict(),\n",
    "                        paths.OUTPUT_DIR + f\"/{config.MODEL.replace('/', '_')}_fold_{fold}_best.pth\")\n",
    "            best_model_predictions = predictions\n",
    "\n",
    "    valid_folds[\"preds\"] = best_model_predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "680ef548-a750-43e5-93ae-18ea1180eba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|                                                                                                                          | 0/3 [00:00<?, ?train_batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.1238e-01,  6.9532e-01, -3.8657e-01,  5.3580e-01,  3.3346e-01,\n",
      "         -2.2080e-01, -3.8812e-01,  8.4809e-02, -7.7118e-01,  3.2834e-01,\n",
      "         -5.7515e-01, -9.8273e-01, -4.0860e-01, -1.0282e-01,  2.0690e-01,\n",
      "          3.0010e-01, -4.7229e-01,  1.0171e+00,  5.5687e-01,  1.5468e-01,\n",
      "          3.9390e-01, -1.9084e-01,  5.8767e-01, -5.4621e-01,  5.3821e-01,\n",
      "         -8.0578e-01,  1.6446e-01],\n",
      "        [ 4.7683e-01, -2.3562e-01, -5.8076e-01, -5.9209e-01, -5.3207e-02,\n",
      "          3.7364e-01, -2.4512e-01, -1.8984e-01, -7.6624e-01,  4.7353e-01,\n",
      "         -5.8160e-01,  8.9750e-03, -3.9828e-01,  6.4202e-01, -1.7590e-02,\n",
      "         -1.6290e-01,  2.2174e-01,  3.8520e-01,  4.0470e-01,  1.6051e-01,\n",
      "          2.0232e-01, -3.6292e-01, -9.2882e-02, -6.0806e-01,  9.5696e-01,\n",
      "         -6.4758e-02,  2.2197e-01],\n",
      "        [ 4.6761e-01,  1.9453e-02, -9.5537e-01, -1.7881e-01, -4.0631e-01,\n",
      "         -2.0258e-01,  3.8512e-01, -2.8105e-01, -1.8331e-01,  1.9198e-01,\n",
      "          7.8092e-01, -2.8922e-01, -8.6714e-01,  7.8470e-01, -6.5535e-01,\n",
      "          2.1602e-01, -3.8472e-01,  6.5658e-01, -6.1592e-02,  2.4412e-01,\n",
      "          4.5623e-01, -6.6257e-02,  6.4335e-01, -2.2629e-01,  1.4653e+00,\n",
      "          2.3076e-01,  5.6040e-01],\n",
      "        [-1.5977e-01, -3.8237e-01,  1.4139e-01,  2.3894e-02,  4.4210e-01,\n",
      "          4.2212e-01,  1.5235e-01, -3.0941e-02,  1.0121e-01,  6.4809e-01,\n",
      "         -4.8619e-01,  9.6177e-02, -5.0295e-01, -1.4555e-01,  6.7238e-02,\n",
      "         -1.0498e-01,  2.7117e-01,  4.9906e-01, -2.6243e-01,  7.0519e-02,\n",
      "         -4.0059e-01, -1.0438e-01, -2.4280e-01, -8.7240e-01,  3.1263e-01,\n",
      "          2.2050e-01,  7.8420e-01],\n",
      "        [-2.4278e-01, -2.0575e-01, -2.3899e-01,  3.6830e-01,  3.7874e-01,\n",
      "          5.1642e-01, -2.0882e-01,  6.7574e-03, -8.8829e-02, -3.8437e-01,\n",
      "         -2.3103e-01, -1.9079e-01,  6.1588e-02,  9.7751e-01,  3.5320e-01,\n",
      "         -5.2338e-01, -4.0322e-01,  8.8357e-01,  6.5140e-01, -7.4169e-01,\n",
      "         -9.0164e-02, -5.3820e-01, -7.9444e-02, -3.2903e-01,  6.8732e-01,\n",
      "         -9.9090e-01,  8.3001e-03],\n",
      "        [-1.8248e-01,  1.5853e-01,  2.6179e-01,  3.0948e-01,  1.0230e-01,\n",
      "          1.0873e-01,  9.8128e-03,  2.7749e-01, -8.4362e-02, -1.6417e-01,\n",
      "         -3.0633e-01, -3.4374e-01,  9.2751e-02,  1.8656e-01,  4.2768e-01,\n",
      "         -1.9025e-01, -3.2006e-01,  8.8020e-01,  3.2866e-01, -4.3808e-01,\n",
      "         -9.0096e-02, -4.0643e-01, -1.2825e-01, -1.8639e-01,  1.3944e-01,\n",
      "         -5.4350e-01,  1.4153e-02],\n",
      "        [ 5.7540e-01,  4.4567e-01,  3.9597e-01, -1.2982e-01, -1.7797e-01,\n",
      "          2.9622e-01, -5.0551e-01, -7.7884e-01, -6.6012e-01, -5.5871e-01,\n",
      "          3.5239e-01, -7.8171e-01,  3.3829e-01, -1.7085e-01, -7.4978e-02,\n",
      "         -4.0489e-01, -3.6699e-02,  8.3069e-01,  2.3400e-01, -1.6515e-01,\n",
      "         -2.9736e-01, -3.8729e-01, -3.4280e-01,  3.9235e-01,  1.7026e-01,\n",
      "         -6.2388e-01, -7.7932e-01],\n",
      "        [ 5.2523e-01,  7.3616e-01, -3.9903e-01,  3.7910e-01,  2.3776e-01,\n",
      "         -4.2803e-01, -5.4841e-02,  2.5845e-02, -3.4847e-01,  5.9417e-01,\n",
      "         -1.7491e-01, -3.0589e-01, -7.2814e-01, -2.4516e-01, -2.4217e-01,\n",
      "          1.0702e-01, -3.4549e-01,  7.3360e-01,  7.5804e-02,  8.3562e-02,\n",
      "          4.5637e-01,  8.9780e-02,  4.7524e-01, -8.0830e-01,  7.0451e-01,\n",
      "         -3.1377e-01,  7.0416e-01],\n",
      "        [-6.5884e-02, -3.4756e-02,  1.4654e-01,  1.4761e-01, -1.0997e-01,\n",
      "          2.8443e-01, -9.2816e-02, -1.8912e-01, -6.2986e-01, -1.3205e-01,\n",
      "         -3.1417e-01,  4.0021e-02,  5.7032e-03,  2.3179e-01, -3.1234e-02,\n",
      "         -2.4090e-01, -3.1546e-01,  7.1010e-01,  8.2521e-01, -3.0530e-01,\n",
      "          7.1883e-02, -3.8882e-01, -3.0212e-01, -2.8784e-01,  2.4792e-01,\n",
      "         -3.7404e-01,  4.6848e-02],\n",
      "        [ 4.9294e-01, -2.7588e-01,  6.1026e-01, -1.4269e-01,  3.1639e-02,\n",
      "          1.3678e-01,  1.6647e-01,  6.3021e-01, -4.8296e-01,  6.2254e-02,\n",
      "         -6.5147e-01, -4.6474e-01, -8.6887e-01, -3.0654e-01,  1.2971e-01,\n",
      "          1.6501e-01, -2.6072e-02,  5.1900e-01,  2.6812e-01, -4.9571e-01,\n",
      "         -3.5490e-01, -4.0701e-01, -4.3531e-02,  9.5982e-03,  2.7236e-01,\n",
      "          6.6475e-01,  2.1832e-01],\n",
      "        [-2.8945e-01,  1.6984e-01,  1.0860e+00,  1.9366e-01, -8.5671e-02,\n",
      "          9.9621e-01,  7.0043e-02, -7.7930e-01, -6.8631e-02,  3.8929e-01,\n",
      "          7.0618e-02, -2.8666e-01,  6.0703e-01,  1.8328e-02,  8.5756e-01,\n",
      "          1.1210e-01,  5.1477e-01,  1.2423e+00,  6.3611e-01, -2.3721e-01,\n",
      "         -3.1243e-01, -8.1306e-01, -9.5372e-01,  6.6721e-01,  4.7972e-01,\n",
      "         -1.1709e+00, -6.4140e-01],\n",
      "        [ 5.4718e-01,  3.6401e-01, -2.3039e-01,  3.5249e-02,  8.8533e-02,\n",
      "         -2.3877e-01, -1.1059e-01,  1.3955e-02, -3.0247e-01,  3.4951e-01,\n",
      "         -6.7618e-02, -2.5698e-01, -7.6223e-01, -5.0090e-03, -3.0620e-01,\n",
      "          3.1282e-02, -1.2232e-01,  3.6885e-01, -1.1080e-01, -3.0121e-02,\n",
      "          1.9034e-01,  7.0568e-02,  3.2155e-01, -3.7379e-01,  5.2909e-01,\n",
      "          9.1273e-02,  4.2535e-01],\n",
      "        [-3.5400e-01, -3.5770e-01,  7.9134e-01,  2.0948e-01,  2.9519e-01,\n",
      "          1.0536e+00, -1.7735e-01, -9.1468e-01, -1.4993e-01,  3.0809e-01,\n",
      "         -2.7364e-01, -3.5037e-01,  2.9825e-01, -2.7861e-01,  5.2884e-01,\n",
      "         -3.9157e-01,  4.5190e-01,  1.1652e+00,  3.9712e-01, -1.3622e-01,\n",
      "         -8.2750e-01, -7.8180e-01, -1.0133e+00, -5.7868e-02,  4.7980e-01,\n",
      "         -4.9923e-01, -1.6077e-01],\n",
      "        [ 5.4034e-01,  3.3988e-01, -6.9162e-01,  4.7304e-01,  6.9907e-01,\n",
      "          4.6601e-01, -3.8025e-01, -2.0975e-01, -5.2859e-01, -5.0525e-01,\n",
      "         -3.5076e-01, -1.1681e+00,  3.6810e-01,  1.5603e-01,  7.9443e-01,\n",
      "         -2.6493e-01, -9.8235e-01,  1.5861e+00,  6.6426e-01, -1.5036e-01,\n",
      "          7.2753e-02, -4.9951e-01,  3.5268e-01, -5.2457e-01,  1.9825e-01,\n",
      "         -1.3234e+00, -4.0888e-01],\n",
      "        [-1.8131e-02, -5.4650e-01, -2.9325e-01, -1.5434e-01, -5.8156e-01,\n",
      "          4.7787e-02,  6.4533e-01, -5.6557e-01,  1.9159e-01, -4.9907e-01,\n",
      "          7.8140e-01, -2.6151e-01, -5.8827e-01,  8.8570e-01, -8.7239e-01,\n",
      "          4.8906e-01, -5.8752e-01,  3.6930e-01,  1.6474e-01,  5.6825e-01,\n",
      "         -1.2884e-02, -2.0527e-01,  4.7665e-01,  3.7748e-01,  7.2923e-01,\n",
      "          3.7884e-01,  1.5989e-01],\n",
      "        [ 2.2579e-01,  5.3481e-01,  4.7849e-01,  2.2478e-01, -1.6079e-01,\n",
      "         -4.1094e-01, -2.0581e-02,  9.9476e-02, -2.6612e-01, -1.2859e-03,\n",
      "          1.0347e-02, -3.2805e-01, -3.2408e-01, -6.7265e-02, -3.0348e-01,\n",
      "         -1.7885e-01, -1.9892e-01,  6.7630e-01,  3.1557e-01, -3.4205e-01,\n",
      "         -2.0942e-02, -1.1763e-01,  6.4113e-03, -5.7123e-03,  5.4409e-01,\n",
      "         -2.3830e-01,  5.2291e-02],\n",
      "        [ 3.6426e-01, -3.3795e-01, -7.4006e-01, -1.2576e-01,  2.0958e-01,\n",
      "          4.2864e-01, -8.4115e-02,  2.3936e-01, -5.1682e-01, -5.7582e-01,\n",
      "         -7.9934e-02, -1.5589e-01, -1.0714e-01,  1.1294e+00,  2.9285e-02,\n",
      "         -3.0344e-01, -5.4376e-01,  6.4788e-01,  5.2659e-01, -5.0696e-01,\n",
      "          2.0614e-01, -2.2122e-01,  3.6212e-01, -5.5206e-01,  5.4089e-01,\n",
      "         -6.6093e-01,  5.1178e-02],\n",
      "        [ 2.4132e-01,  3.4563e-02, -5.8235e-02, -2.5198e-01, -4.8015e-02,\n",
      "         -4.1301e-02, -2.2812e-01,  7.8932e-02, -1.3054e-01,  1.3550e-01,\n",
      "         -3.3922e-01, -2.6763e-01, -1.1923e-01,  6.2117e-01, -9.2805e-02,\n",
      "         -8.6466e-02,  1.3675e-01,  1.6615e-01, -1.0718e-01,  2.1665e-01,\n",
      "         -6.7201e-02, -1.4028e-02,  7.8996e-02, -2.2681e-01,  2.3588e-01,\n",
      "         -2.3022e-01, -1.3007e-02],\n",
      "        [-1.3109e+00, -6.1539e-01, -3.9208e-02,  5.1738e-01, -1.5337e-01,\n",
      "          5.9418e-01,  5.2796e-01, -1.1891e-01,  5.6179e-01, -1.5284e-01,\n",
      "         -7.7783e-01, -4.6537e-01, -1.1021e-01,  3.2177e-01,  3.6604e-01,\n",
      "          3.5895e-01, -5.6223e-01,  9.6093e-01,  2.1293e-01,  5.2884e-01,\n",
      "         -2.4367e-01, -1.2276e+00, -2.4774e-01, -7.9961e-01,  3.2644e-01,\n",
      "         -2.6502e-01,  9.8402e-01],\n",
      "        [ 5.8051e-02, -1.4474e-01, -3.4953e-02,  4.9337e-02,  1.5612e-01,\n",
      "          7.7934e-02, -4.2716e-01, -1.7566e-01, -2.8803e-01, -2.9463e-01,\n",
      "         -5.2271e-01, -2.3343e-01, -9.6145e-02,  4.4390e-01, -2.1282e-01,\n",
      "         -2.0723e-01, -3.1561e-02,  2.0335e-01,  2.1142e-01,  1.1695e-01,\n",
      "         -2.2139e-01, -3.1194e-01,  2.9083e-02, -4.7166e-01,  2.0160e-01,\n",
      "         -4.5228e-01,  1.4534e-01],\n",
      "        [ 2.7456e-01, -3.0150e-01,  3.1445e-01,  1.0035e-01,  1.4810e-01,\n",
      "          4.3037e-01, -1.2530e-01, -2.9060e-01, -4.7661e-01, -1.2122e-01,\n",
      "         -1.5369e-01, -1.3326e-01,  9.5612e-03,  3.4173e-01, -1.2683e-01,\n",
      "          7.3471e-02,  1.1033e-01,  5.0500e-01,  4.9118e-01,  2.2812e-03,\n",
      "         -2.5054e-01, -1.6738e-01, -6.4217e-02, -1.9302e-01,  2.0117e-01,\n",
      "         -5.5294e-01, -3.9611e-02],\n",
      "        [ 2.2774e-01,  5.1873e-01,  6.6305e-01,  5.5661e-02, -6.2178e-01,\n",
      "         -1.6000e-01,  9.7955e-02, -5.2727e-01, -4.6152e-01, -1.9067e-01,\n",
      "          6.1992e-01, -4.8380e-01,  2.1003e-01, -8.8119e-02, -4.5501e-01,\n",
      "         -1.1784e-01, -9.2087e-02,  9.9564e-01,  4.2150e-01, -8.5806e-03,\n",
      "         -9.5532e-02, -2.1884e-01, -2.7024e-01,  3.4357e-01,  5.8913e-01,\n",
      "         -4.3237e-01, -3.6048e-01],\n",
      "        [ 2.8678e-01, -1.8788e-01,  8.9158e-02, -1.5464e-01, -2.7665e-01,\n",
      "         -3.8254e-01, -1.7066e-01, -9.6918e-03, -3.6754e-01,  3.4791e-01,\n",
      "         -3.4234e-01, -5.6269e-01, -9.7383e-02,  5.3954e-01, -2.7886e-01,\n",
      "         -3.4733e-01, -1.5246e-01,  5.2447e-01,  3.5509e-01,  4.1094e-01,\n",
      "         -3.8153e-01,  1.9149e-01, -5.2092e-02,  1.2798e-01,  3.5481e-01,\n",
      "          5.5497e-01, -3.6474e-01],\n",
      "        [ 1.2907e-01,  3.9765e-01,  7.6114e-01,  2.0087e-01, -1.9480e-01,\n",
      "          9.3577e-02,  3.0625e-01,  2.0360e-01, -7.3716e-01,  2.7123e-01,\n",
      "         -4.0441e-01, -2.7942e-01,  1.7228e-01, -8.2915e-01,  6.4528e-01,\n",
      "          4.0783e-01,  1.7479e-02,  1.2660e+00,  6.5710e-01, -1.3677e-01,\n",
      "          1.1367e-01, -6.4191e-01, -3.4024e-01, -2.0628e-01,  1.4216e-01,\n",
      "         -4.4560e-01,  1.0643e-01],\n",
      "        [ 7.7708e-01,  1.5214e-01,  2.8747e-01, -4.2305e-01, -1.9914e-01,\n",
      "          3.1591e-01, -3.6565e-02, -3.9580e-01, -7.6969e-01,  3.2111e-01,\n",
      "          2.5512e-01, -1.6601e-01,  2.2682e-01,  2.0653e-01,  1.2967e-01,\n",
      "          2.0478e-01,  4.7843e-01,  7.1246e-01,  3.8921e-01,  1.3802e-01,\n",
      "          6.1245e-02, -6.8707e-02, -1.4878e-01,  2.4534e-01,  5.1842e-01,\n",
      "         -5.6440e-01, -5.1712e-01],\n",
      "        [-4.1441e-02, -6.8983e-02, -6.9120e-01, -1.9331e-01, -5.8213e-02,\n",
      "          4.7685e-01,  4.1196e-02, -2.4768e-01,  2.8226e-03, -9.0081e-01,\n",
      "          2.7229e-01, -5.2163e-01, -1.9744e-01,  7.5051e-01, -3.7900e-02,\n",
      "         -5.0821e-01, -9.2751e-01,  8.0695e-01,  1.3180e-01, -4.3642e-01,\n",
      "          6.1480e-02, -5.7705e-01,  1.0806e-01, -1.4303e-01,  4.9547e-01,\n",
      "         -3.0325e-01, -9.1273e-02],\n",
      "        [-2.0267e-01, -1.2945e-01, -1.1685e+00,  7.5111e-01, -4.4647e-01,\n",
      "         -8.0317e-01, -7.4609e-01,  2.0367e-02, -8.7266e-01, -8.4529e-01,\n",
      "         -9.5436e-01, -1.0385e+00, -1.1198e-01,  7.5602e-01, -1.3308e-01,\n",
      "          1.1423e-01, -1.0842e+00,  5.1434e-01,  8.5904e-01,  6.8218e-01,\n",
      "          3.4195e-01, -1.0072e+00,  6.8933e-01, -6.1295e-01,  3.8723e-01,\n",
      "         -1.8590e-01,  4.5695e-01],\n",
      "        [-1.5184e-02,  8.3062e-02,  1.6382e-01, -2.7994e-01, -6.3450e-02,\n",
      "          4.8415e-03,  3.5746e-01,  4.9612e-01,  6.5021e-02,  4.1844e-02,\n",
      "         -1.0466e-01, -1.5013e-01, -5.1602e-01,  3.2066e-01,  1.8178e-01,\n",
      "         -2.5474e-01,  1.5041e-02,  8.1837e-01,  7.1908e-02, -6.7251e-01,\n",
      "         -7.1962e-02, -5.9203e-01, -8.0691e-02, -2.2379e-01,  1.2225e+00,\n",
      "         -1.2034e-01,  3.3711e-01],\n",
      "        [ 3.8576e-01,  4.3215e-01, -5.9366e-02,  3.1057e-01,  4.4445e-01,\n",
      "         -6.6600e-02,  1.3767e-01, -3.2028e-01, -4.3633e-02,  3.5092e-01,\n",
      "          2.1102e-02, -1.9438e-01, -7.5075e-01, -3.8535e-01, -3.4458e-01,\n",
      "          1.8169e-02, -4.1001e-01,  7.3720e-01,  9.7239e-02,  9.2148e-03,\n",
      "          7.4030e-02,  9.5121e-02,  2.9027e-01, -5.3278e-01,  5.4241e-01,\n",
      "         -1.8072e-01,  4.9124e-01],\n",
      "        [ 2.8456e-01, -2.7716e-01, -4.0782e-01,  2.1276e-01, -3.6723e-02,\n",
      "         -3.2250e-01, -1.0677e+00, -2.3905e-01, -7.3224e-01,  2.3347e-02,\n",
      "         -8.2231e-01, -5.7999e-01, -5.5150e-01,  6.3154e-01, -4.1622e-01,\n",
      "         -6.3880e-01, -2.2732e-01, -7.2601e-02,  3.9639e-01,  7.8605e-02,\n",
      "         -3.1711e-01, -1.2108e-01, -1.7816e-02, -7.2776e-02,  2.0579e-01,\n",
      "          6.5386e-01, -5.8972e-02],\n",
      "        [ 5.0176e-01, -2.2117e-01, -2.2612e-01, -5.5325e-02,  3.2227e-01,\n",
      "          4.7594e-02, -7.6866e-02,  1.4252e-01, -4.0928e-01, -3.1077e-02,\n",
      "         -2.0937e-01,  8.3593e-02, -4.5912e-01,  4.1016e-01, -2.7541e-01,\n",
      "          5.0009e-02, -8.6126e-02,  1.8450e-01,  1.6677e-01, -6.8848e-02,\n",
      "          2.9422e-02,  1.6175e-01,  3.8714e-01, -5.2621e-01,  2.0869e-01,\n",
      "         -1.4737e-01,  3.1469e-01],\n",
      "        [ 2.2491e-01,  2.9310e-02,  1.8850e-01, -9.2043e-02, -1.5744e-01,\n",
      "         -1.7776e-01, -5.5206e-03,  3.5549e-03, -1.5789e-01, -2.3860e-01,\n",
      "          7.2601e-02, -1.9312e-01, -2.2093e-01,  3.3047e-01, -3.3808e-01,\n",
      "         -7.6437e-03, -1.2795e-01,  2.4981e-01,  4.2575e-02,  1.3172e-02,\n",
      "         -1.0749e-01,  3.6692e-03,  1.4734e-01,  6.7077e-02,  1.3008e-01,\n",
      "         -1.7730e-02, -5.3287e-02]], grad_fn=<AddmmBackward0>) tensor([ 1., 15., 12., 10., 15., 15., 13.,  1.,  2., 12., 28.,  1., 23., 15.,\n",
      "        14., 21.,  1., 26., 15.,  1., 15., 27., 15.,  3., 25., 15., 15.,  4.,\n",
      "         1.,  1., 14., 15.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 28 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[245], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mFOLDS):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fold \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 12\u001b[0m         _oof_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m         oof_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([oof_df, _oof_df])\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# print(f\"========== Fold: {fold} result ==========\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[244], line 59\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(folds, fold)\u001b[0m\n\u001b[1;32m     56\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# ======= TRAIN ==========\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# ======= EVALUATION ==========\u001b[39;00m\n\u001b[1;32m     62\u001b[0m avg_val_loss, prediction_dict \u001b[38;5;241m=\u001b[39m valid_epoch(valid_loader, model, criterion, device)\n",
      "Cell \u001b[0;32mIn[243], line 54\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, scheduler, device)\u001b[0m\n\u001b[1;32m     52\u001b[0m     y_preds \u001b[38;5;241m=\u001b[39m model(inputs) \u001b[38;5;66;03m# forward propagation pass\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y_preds, labels)\n\u001b[0;32m---> 54\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# get loss\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mGRADIENT_ACCUMULATION_STEPS \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     56\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m config\u001b[38;5;241m.\u001b[39mGRADIENT_ACCUMULATION_STEPS\n",
      "File \u001b[0;32m~/Desktop/mobile/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/mobile/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/mobile/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/mobile/venv/lib/python3.8/site-packages/torch/nn/functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3052\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 28 is out of bounds."
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    def get_result(oof_df):\n",
    "        labels = oof_df[\"generated\"].values\n",
    "        preds = oof_df[\"preds\"].values\n",
    "        score = get_score(labels, preds)\n",
    "        # print(f'Score: {score:<.4f}')\n",
    "    \n",
    "    if config.TRAIN:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(config.FOLDS):\n",
    "            if fold == 0:\n",
    "                _oof_df = train_loop(train_df, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                # print(f\"========== Fold: {fold} result ==========\")\n",
    "                get_result(_oof_df)\n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        # print(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "        oof_df.to_csv(paths.OUTPUT_DIR + '/oof_df.csv', index=False)\n",
    "    if config.WANDB:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4ac5b287-a255-4d79-b1bb-5ca91950c58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'vkcup2022-first-stage'...\n",
      "remote: Enumerating objects: 12, done.\u001b[K\n",
      "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
      "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
      "remote: Total 12 (delta 2), reused 8 (delta 2), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (12/12), 27.99 KiB | 187.00 KiB/s, done.\n",
      "Resolving deltas: 100% (2/2), done.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5872e990-5d9e-47a0-8fe4-f58bb2b0dc63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
